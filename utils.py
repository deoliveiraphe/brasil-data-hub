"""
Utilit√°rios para limpeza e manuten√ß√£o de arquivos de dados.
"""

import os
import glob
from pathlib import Path
from typing import List


def clean_old_files(directory: str, pattern: str, keep_count: int) -> int:
    """
    Remove arquivos antigos mantendo apenas os mais recentes.
    
    Args:
        directory (str): Diret√≥rio onde buscar os arquivos
        pattern (str): Padr√£o de nome dos arquivos (ex: 'aerodromos_privados_*.json')
        keep_count (int): Quantidade de arquivos mais recentes para manter
        
    Returns:
        int: N√∫mero de arquivos removidos
    """
    files_pattern = os.path.join(directory, pattern)
    files = glob.glob(files_pattern)
    
    if len(files) <= keep_count:
        return 0
    
    # Ordenar por data de modifica√ß√£o (mais recentes primeiro)
    files.sort(key=os.path.getmtime, reverse=True)
    
    # Arquivos para remover (todos exceto os mais recentes)
    files_to_remove = files[keep_count:]
    
    removed_count = 0
    for file_path in files_to_remove:
        try:
            os.remove(file_path)
            removed_count += 1
            print(f"   üóëÔ∏è Removido: {Path(file_path).name}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro ao remover {file_path}: {e}")
    
    return removed_count


def cleanup_data_files(scraper_name: str) -> None:
    """
    Limpa arquivos antigos de um scraper espec√≠fico.
    
    Mant√©m:
    - 1 arquivo raw mais recente
    - 2 arquivos processed mais recentes
    
    Args:
        scraper_name (str): Nome base do scraper (ex: 'aerodromos_privados')
    """
    print(f"üßπ Limpando arquivos antigos de {scraper_name}...")
    
    # Limpar arquivos raw (manter apenas 1)
    raw_removed = clean_old_files(
        directory='data/raw',
        pattern=f'{scraper_name}_raw_*.json',
        keep_count=1
    )
    
    # Limpar arquivos processed (manter apenas 2)
    processed_removed = clean_old_files(
        directory='data/processed',
        pattern=f'{scraper_name}_*.json',
        keep_count=2
    )
    
    total_removed = raw_removed + processed_removed
    
    if total_removed > 0:
        print(f"‚úÖ Limpeza conclu√≠da: {total_removed} arquivos removidos")
        print(f"   üìÑ Raw: {raw_removed} removidos (mantendo 1)")
        print(f"   üìã Processed: {processed_removed} removidos (mantendo 2)")
    else:
        print("‚úÖ Nenhum arquivo antigo encontrado para remo√ß√£o")


def cleanup_all_data_files() -> None:
    """
    Limpa arquivos antigos de todos os scrapers conhecidos.
    """
    print("üßπ Iniciando limpeza geral de arquivos antigos...")
    
    scrapers = [
        'aerodromos_privados',
        'aerodromos_publicos'
    ]
    
    total_cleaned = 0
    
    for scraper in scrapers:
        print(f"\n{'='*50}")
        cleanup_data_files(scraper)
        total_cleaned += 1
    
    print(f"\n‚úÖ Limpeza geral conclu√≠da para {total_cleaned} scrapers")


if __name__ == '__main__':
    # Executar limpeza geral se chamado diretamente
    cleanup_all_data_files()
